# Credit-Card-Fraud-Detection-Multi-Machine-Learning-Algorithms
An elaborate programming research study and program to detect Credit Card Fraud in considered dataset from Kaggle using Multiple Machine learning algorithms. The repository contains a .ipynb python3 notebook and .py files of the program. Dataset used can be downloaded from kaggle link given below.

# Machine Learning Algorithms Applied
Primarily GaussainNB, DecisionTreeClassifier, K-Nearest Neighbors and Support Vector Machines are used in this script. Alongwith with these multiple variants of these algorithms are used for analysis and comparison purposes.
Since the Dataset used is highly unbalanced. Certain Resampling, Reshuffling and Scaling Techniques are used to get a balanced dataset.
https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets - This kernel notebook was referred for handling the unbalanced biased data.

# List of Algorithms with Variants
Below given is list of machine learning algorithms applied and their variants
1. GaussainNB
2. DecisionTreeClassifier
              i. Unprunned DCT
              ii. Prunned DCT
3. K-Nearest Neighbors
4. Support Vector Machines
              i. Linear Kernel
              ii. Sigmoid Kernel
              iii. rbf Kernel

# List of Metrics Considered
Below given is list of performance metrics considered for analysis of algorithm predictions
1. Accuracy Score - In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must                         exactly match the corresponding set of labels in y_true.
2. Balanced Accuracy Score - The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is                              defined as the average of recall obtained on each class.
3. Precision Score - The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.
4. Recall Score - The recall is intuitively the ability of the classifier to find all the positive samples.
5. F Score - The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its              best value at 1 and worst score at 0.

# The Python Notebooks were created and executed on Google Colaboratory
It is best advised to use the python notebooks in google colab to achieve best results.

# Some Important and Useful Links:
Kaggle -Credit-Card-Fraud- Dataset Link: https://www.kaggle.com/mlg-ulb/creditcardfraud </br>
Scikit-learn Link: https://scikit-learn.org/

In case of any suggestions, corrections and contributions kindly drop a mail at husain.amreliwala52@gmail.com

- Happy Machine and Deep Learning!!
